{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "02.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zedVxlEl2AbZ"
      },
      "source": [
        "# Assignment 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaOt4tUD5Lft"
      },
      "source": [
        "Dear students,\n",
        "\n",
        "The second worksheet is now available [here](https://mycampus.imp.fu-berlin.de/portal/directtool/c206efd7-b97b-481e-86e4-7210cd66f639/). You will have time until next Friday, 16:00 MEST.\n",
        "\n",
        "Some torch classes that might come in handy:\n",
        "\n",
        "* [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "\n",
        "* [torch.nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "\n",
        "* [torch.nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html?highlight=softmax#torch.nn.Softmax) (for \"one-hot encoding\")\n",
        "\n",
        "Best,\n",
        "Your tutors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU14KQ0d5a1p"
      },
      "source": [
        "You are given MNIST-type training data of images with handwritten digits. The data consists of training images with associated labels in $\\{0,1,\\dots,9\\}$ and an unlabeled test set.\n",
        "\n",
        "Your task is to train a neural network model of your choice to predict the digit from the image.\n",
        "\n",
        "As a submission, please upload the prediction of digits for the test set exactly as shown below.\n",
        "\n",
        "For this prediction, we will use the following grading scheme:\n",
        "\n",
        "| accuracy | points |\n",
        "|----------|--------|\n",
        "| ≥50%     | 5      |\n",
        "| ≥75%     | 7      |\n",
        "| ≥90%     | 10     |\n",
        " \n",
        "\n",
        "If you present your work in the tutorial, be prepared to show your code, explain how you prepared the data, how you chose the network architecture and other hyperparameters, how you validated the model, and show the convergence of the training error.\n",
        "\n",
        "\n",
        "To load and visualize the data, please refer to the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "fxlDCNYO2Abb",
        "outputId": "1b1738f6-a362-4e10-844b-786d8bf76371"
      },
      "source": [
        "import io\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "response = requests.get('https://github.com/jneuendorf/deeplearning-lecture-21/blob/main/02/prediction-challenge-01-data.npz?raw=true')\n",
        "with np.load(io.BytesIO(response.content)) as fh:\n",
        "    data_x = fh['data_x']\n",
        "    data_y = fh['data_y']\n",
        "    test_x = fh['test_x']\n",
        "\n",
        "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
        "# 1. INDEX: IMAGE SERIAL NUMBER\n",
        "# 2. INDEX: COLOR CHANNEL\n",
        "# 3/4. INDEX: PIXEL VALUE\n",
        "print(data_x.shape, data_x.dtype)\n",
        "print(data_y.shape, data_y.dtype)\n",
        "\n",
        "# TEST DATA: INPUT (x) ONLY\n",
        "print(test_x.shape, test_x.dtype)\n",
        "\n",
        "plt.imshow(data_x[0, 0])\n",
        "plt.title(data_y[0])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 1, 28, 28) float32\n",
            "(20000,) int64\n",
            "(2000, 1, 28, 28) float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6hLrTIx2Abb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgzd5ClY8N7r"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dGHqxtX8TGv",
        "outputId": "3dd78493-ee5e-4a88-da00-d6733f5c5da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))\n",
        "\n",
        "\n",
        "class Mnist(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.lin_relu = nn.Sequential(\n",
        "            nn.Linear(data_x.shape[2] * data_x.shape[3], 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.lin_relu(x)\n",
        "\n",
        "\n",
        "model = Mnist().to(device)\n",
        "print(model)\n",
        "\n",
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "learning_rate = 1e-3\n",
        "optim = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_samples = 100\n",
        "n_iterations = 50_000\n",
        "\n",
        "for it in range(n_iterations):\n",
        "    optim.zero_grad()                            \n",
        "    x = torch.rand(n_samples) * 2 - 1            \n",
        "    y_pred = model(x)      \n",
        "    y_true = f(x)                                \n",
        "    loss = loss_function(y_true, y_pred)         \n",
        "    loss.backward()                                                                          \n",
        "    optim.step()                                 \n",
        "    print(f\"iteration {it}, mean-squared error is {loss.item():.4}\", end=\"\\r\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Mnist(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (lin_relu): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n",
            "Predicted class: tensor([0], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e52b371d6fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-e52b371d6fdf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/flatten.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd45o6DP6BiZ"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAEMNkwy6LEZ"
      },
      "source": [
        "Use your trained model to predict the digits for the test data. Store the prediction as shown in the code snippet below and upload your prediction file.\n",
        "\n",
        "Please note that you need to use exactly the shown file format, file name, and array shape as shown in the code snippet. Otherwise, we might not be able to correctly process your submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENwp0Nlz6NWz",
        "outputId": "f4b078cf-7760-4065-8b97-2f7cce73906e"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "prediction = torch.zeros(2000)  # THAT'S YOUR JOB\n",
        "print(prediction.ndim)\n",
        "\n",
        "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
        "assert prediction.ndim == 1\n",
        "assert prediction.shape[0] == 2000\n",
        "\n",
        "# AND SAVE EXACTLY AS SHOWN BELOW\n",
        "np.save('prediction.npy', prediction)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}